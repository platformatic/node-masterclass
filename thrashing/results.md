# Experimental results

## `server.js`

```bash
$ autocannon -c 10 -r 50 -d 60 --renderStatusCodes http://127.0.0.1:3000
Running 60s test @ http://127.0.0.1:3000
10 connections


┌─────────┬──────┬────────┬────────┬────────┬───────────┬──────────┬────────┐
│ Stat    │ 2.5% │ 50%    │ 97.5%  │ 99%    │ Avg       │ Stdev    │ Max    │
├─────────┼──────┼────────┼────────┼────────┼───────────┼──────────┼────────┤
│ Latency │ 7 ms │ 128 ms │ 251 ms │ 257 ms │ 128.48 ms │ 74.07 ms │ 297 ms │
└─────────┴──────┴────────┴────────┴────────┴───────────┴──────────┴────────┘
┌───────────┬─────────┬─────────┬─────────┬─────────┬─────────┬───────┬─────────┐
│ Stat      │ 1%      │ 2.5%    │ 50%     │ 97.5%   │ Avg     │ Stdev │ Min     │
├───────────┼─────────┼─────────┼─────────┼─────────┼─────────┼───────┼─────────┤
│ Req/Sec   │ 37      │ 37      │ 39      │ 40      │ 39      │ 0.71  │ 37      │
├───────────┼─────────┼─────────┼─────────┼─────────┼─────────┼───────┼─────────┤
│ Bytes/Sec │ 6.51 kB │ 6.51 kB │ 6.87 kB │ 7.04 kB │ 6.87 kB │ 124 B │ 6.51 kB │
└───────────┴─────────┴─────────┴─────────┴─────────┴─────────┴───────┴─────────┘
┌──────┬───────┐
│ Code │ Count │
├──────┼───────┤
│ 200  │ 2340  │
└──────┴───────┘

Req/Bytes counts sampled once per second.
# of samples: 60

3k requests in 60.07s, 412 kB read
```

Conclusions:
1. the server can only take 39 req/s on average

---

```bash
autocannon -c 10 -R 20 -d 60 -t 1 --renderStatusCodes http://127.0.0.1:3000
Running 60s test @ http://127.0.0.1:3000
10 connections


┌─────────┬──────┬────────┬────────┬────────┬───────────┬──────────┬────────┐
│ Stat    │ 2.5% │ 50%    │ 97.5%  │ 99%    │ Avg       │ Stdev    │ Max    │
├─────────┼──────┼────────┼────────┼────────┼───────────┼──────────┼────────┤
│ Latency │ 5 ms │ 107 ms │ 245 ms │ 252 ms │ 113.62 ms │ 71.95 ms │ 276 ms │
└─────────┴──────┴────────┴────────┴────────┴───────────┴──────────┴────────┘
┌───────────┬─────────┬─────────┬─────────┬─────────┬─────────┬───────┬─────────┐
│ Stat      │ 1%      │ 2.5%    │ 50%     │ 97.5%   │ Avg     │ Stdev │ Min     │
├───────────┼─────────┼─────────┼─────────┼─────────┼─────────┼───────┼─────────┤
│ Req/Sec   │ 20      │ 20      │ 20      │ 20      │ 20      │ 0     │ 20      │
├───────────┼─────────┼─────────┼─────────┼─────────┼─────────┼───────┼─────────┤
│ Bytes/Sec │ 3.52 kB │ 3.52 kB │ 3.52 kB │ 3.52 kB │ 3.52 kB │ 0 B   │ 3.52 kB │
└───────────┴─────────┴─────────┴─────────┴─────────┴─────────┴───────┴─────────┘
┌──────┬───────┐
│ Code │ Count │
├──────┼───────┤
│ 200  │ 1200  │
└──────┴───────┘

Req/Bytes counts sampled once per second.
# of samples: 60

1k requests in 60.07s, 211 kB read
```

Conclusions:
* Keeping the server under its peak utilization keeps the latency under the
  request arrival rate.

---

```bash
autocannon -c 50 -R 42 -d 60 --renderStatusCodes http://127.0.0.1:3000
Running 60s test @ http://127.0.0.1:3000
50 connections


┌─────────┬───────┬────────┬─────────┬─────────┬───────────┬───────────┬─────────┐
│ Stat    │ 2.5%  │ 50%    │ 97.5%   │ 99%     │ Avg       │ Stdev     │ Max     │
├─────────┼───────┼────────┼─────────┼─────────┼───────────┼───────────┼─────────┤
│ Latency │ 24 ms │ 473 ms │ 1000 ms │ 1020 ms │ 486.75 ms │ 293.19 ms │ 1054 ms │
└─────────┴───────┴────────┴─────────┴─────────┴───────────┴───────────┴─────────┘
┌───────────┬─────────┬─────────┬─────────┬─────────┬─────────┬───────┬─────────┐
│ Stat      │ 1%      │ 2.5%    │ 50%     │ 97.5%   │ Avg     │ Stdev │ Min     │
├───────────┼─────────┼─────────┼─────────┼─────────┼─────────┼───────┼─────────┤
│ Req/Sec   │ 40      │ 40      │ 41      │ 42      │ 40.72   │ 0.64  │ 40      │
├───────────┼─────────┼─────────┼─────────┼─────────┼─────────┼───────┼─────────┤
│ Bytes/Sec │ 7.04 kB │ 7.04 kB │ 7.22 kB │ 7.39 kB │ 7.17 kB │ 112 B │ 7.04 kB │
└───────────┴─────────┴─────────┴─────────┴─────────┴─────────┴───────┴─────────┘
┌──────┬───────┐
│ Code │ Count │
├──────┼───────┤
│ 200  │ 2443  │
└──────┴───────┘

Req/Bytes counts sampled once per second.
# of samples: 60

2k requests in 60.05s, 430 kB read
```

Conclusions:
* just tipping over the 41 req/s have the max latency going over the 1s mark.

---


```
autocannon -c 50 -r 50 -d 60 --renderStatusCodes http://127.0.0.1:3000
Running 60s test @ http://127.0.0.1:3000
50 connections


┌─────────┬───────┬────────┬─────────┬─────────┬───────────┬───────────┬─────────┐
│ Stat    │ 2.5%  │ 50%    │ 97.5%   │ 99%     │ Avg       │ Stdev     │ Max     │
├─────────┼───────┼────────┼─────────┼─────────┼───────────┼───────────┼─────────┤
│ Latency │ 31 ms │ 612 ms │ 1199 ms │ 1219 ms │ 613.35 ms │ 355.13 ms │ 1275 ms │
└─────────┴───────┴────────┴─────────┴─────────┴───────────┴───────────┴─────────┘
┌───────────┬─────────┬─────────┬─────────┬─────────┬─────────┬───────┬─────────┐
│ Stat      │ 1%      │ 2.5%    │ 50%     │ 97.5%   │ Avg     │ Stdev │ Min     │
├───────────┼─────────┼─────────┼─────────┼─────────┼─────────┼───────┼─────────┤
│ Req/Sec   │ 39      │ 40      │ 41      │ 42      │ 40.67   │ 0.63  │ 39      │
├───────────┼─────────┼─────────┼─────────┼─────────┼─────────┼───────┼─────────┤
│ Bytes/Sec │ 6.87 kB │ 7.04 kB │ 7.22 kB │ 7.39 kB │ 7.16 kB │ 110 B │ 6.86 kB │
└───────────┴─────────┴─────────┴─────────┴─────────┴─────────┴───────┴─────────┘
┌──────┬───────┐
│ Code │ Count │
├──────┼───────┤
│ 200  │ 2440  │
└──────┴───────┘

Req/Bytes counts sampled once per second.
# of samples: 60

5k requests in 60.07s, 429 kB read
```

Catastrophic failure, top latency goes over 1 second.

---

If connections are truncanted after 1 second of waiting, e.g. every second
we get a fresh set of 50 connections, we start seeing timeouts and no requests
are completed in a given second.

```bash
$ autocannon -c 50 -r 50 -d 60 -t 1 --renderStatusCodes http://127.0.0.1:3000
Running 60s test @ http://127.0.0.1:3000
50 connections


┌─────────┬───────┬────────┬────────┬────────┬───────────┬───────────┬────────┐
│ Stat    │ 2.5%  │ 50%    │ 97.5%  │ 99%    │ Avg       │ Stdev     │ Max    │
├─────────┼───────┼────────┼────────┼────────┼───────────┼───────────┼────────┤
│ Latency │ 13 ms │ 290 ms │ 834 ms │ 893 ms │ 329.87 ms │ 232.97 ms │ 979 ms │
└─────────┴───────┴────────┴────────┴────────┴───────────┴───────────┴────────┘
┌───────────┬─────┬──────┬─────┬───────┬───────┬───────┬─────────┐
│ Stat      │ 1%  │ 2.5% │ 50% │ 97.5% │ Avg   │ Stdev │ Min     │
├───────────┼─────┼──────┼─────┼───────┼───────┼───────┼─────────┤
│ Req/Sec   │ 0   │ 0    │ 0   │ 0     │ 0.67  │ 5.13  │ 40      │
├───────────┼─────┼──────┼─────┼───────┼───────┼───────┼─────────┤
│ Bytes/Sec │ 0 B │ 0 B  │ 0 B │ 0 B   │ 117 B │ 902 B │ 7.04 kB │
└───────────┴─────┴──────┴─────┴───────┴───────┴───────┴─────────┘
┌──────┬───────┐
│ Code │ Count │
├──────┼───────┤
│ 200  │ 40    │
└──────┴───────┘

Req/Bytes counts sampled once per second.
# of samples: 60

5k requests in 60.06s, 7.04 kB read
3k errors (3k timeouts)
```

## `server-protected.js`

```bash
$autocannon -c 10 -r 50 -d 60 --renderStatusCodes http://127.0.0.1:3000
Running 60s test @ http://127.0.0.1:3000
10 connections


┌─────────┬──────┬────────┬────────┬────────┬───────────┬──────────┬────────┐
│ Stat    │ 2.5% │ 50%    │ 97.5%  │ 99%    │ Avg       │ Stdev    │ Max    │
├─────────┼──────┼────────┼────────┼────────┼───────────┼──────────┼────────┤
│ Latency │ 7 ms │ 128 ms │ 249 ms │ 254 ms │ 127.83 ms │ 73.63 ms │ 285 ms │
└─────────┴──────┴────────┴────────┴────────┴───────────┴──────────┴────────┘
┌───────────┬─────────┬─────────┬─────────┬─────────┬────────┬───────┬─────────┐
│ Stat      │ 1%      │ 2.5%    │ 50%     │ 97.5%   │ Avg    │ Stdev │ Min     │
├───────────┼─────────┼─────────┼─────────┼─────────┼────────┼───────┼─────────┤
│ Req/Sec   │ 37      │ 38      │ 39      │ 40      │ 39.21  │ 0.68  │ 37      │
├───────────┼─────────┼─────────┼─────────┼─────────┼────────┼───────┼─────────┤
│ Bytes/Sec │ 6.51 kB │ 6.69 kB │ 6.87 kB │ 7.04 kB │ 6.9 kB │ 119 B │ 6.51 kB │
└───────────┴─────────┴─────────┴─────────┴─────────┴────────┴───────┴─────────┘
┌──────┬───────┐
│ Code │ Count │
├──────┼───────┤
│ 200  │ 2352  │
└──────┴───────┘

Req/Bytes counts sampled once per second.
# of samples: 60

3k requests in 60.07s, 414 kB read
```

---

```bash
$ autocannon -c 50 -r 50 -d 60 --renderStatusCodes http://127.0.0.1:3000
Running 60s test @ http://127.0.0.1:3000
50 connections


┌─────────┬──────┬────────┬─────────┬─────────┬───────────┬───────────┬─────────┐
│ Stat    │ 2.5% │ 50%    │ 97.5%   │ 99%     │ Avg       │ Stdev     │ Max     │
├─────────┼──────┼────────┼─────────┼─────────┼───────────┼───────────┼─────────┤
│ Latency │ 1 ms │ 444 ms │ 1165 ms │ 1201 ms │ 489.28 ms │ 346.62 ms │ 1252 ms │
└─────────┴──────┴────────┴─────────┴─────────┴───────────┴───────────┴─────────┘
┌───────────┬─────────┬─────────┬─────────┬────────┬─────────┬─────────┬─────────┐
│ Stat      │ 1%      │ 2.5%    │ 50%     │ 97.5%  │ Avg     │ Stdev   │ Min     │
├───────────┼─────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┤
│ Req/Sec   │ 40      │ 40      │ 41      │ 2573   │ 1283.12 │ 1242.84 │ 40      │
├───────────┼─────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┤
│ Bytes/Sec │ 7.04 kB │ 7.04 kB │ 7.22 kB │ 805 kB │ 399 kB  │ 392 kB  │ 7.04 kB │
└───────────┴─────────┴─────────┴─────────┴────────┴─────────┴─────────┴─────────┘
┌──────┬───────┐
│ Code │ Count │
├──────┼───────┤
│ 200  │ 1500  │
├──────┼───────┤
│ 503  │ 75463 │
└──────┴───────┘

Req/Bytes counts sampled once per second.
# of samples: 60

1500 2xx responses, 75463 non 2xx responses
79k requests in 60.06s, 24 MB read
```

Conclusions:
* less successful req/s are processed
* the server is always responsive but return a 503


---

```bash
$ autocannon -c 50 -r 50 -d 60 -t 1 --renderStatusCodes http://127.0.0.1:3000
Running 60s test @ http://127.0.0.1:3000
50 connections


┌─────────┬──────┬────────┬────────┬────────┬───────────┬───────────┬─────────┐
│ Stat    │ 2.5% │ 50%    │ 97.5%  │ 99%    │ Avg       │ Stdev     │ Max     │
├─────────┼──────┼────────┼────────┼────────┼───────────┼───────────┼─────────┤
│ Latency │ 0 ms │ 253 ms │ 827 ms │ 891 ms │ 296.02 ms │ 240.67 ms │ 1000 ms │
└─────────┴──────┴────────┴────────┴────────┴───────────┴───────────┴─────────┘
┌───────────┬─────┬──────┬────────┬────────┬─────────┬─────────┬─────────┐
│ Stat      │ 1%  │ 2.5% │ 50%    │ 97.5%  │ Avg     │ Stdev   │ Min     │
├───────────┼─────┼──────┼────────┼────────┼─────────┼─────────┼─────────┤
│ Req/Sec   │ 0   │ 0    │ 1297   │ 3003   │ 1306.69 │ 1272.53 │ 40      │
├───────────┼─────┼──────┼────────┼────────┼─────────┼─────────┼─────────┤
│ Bytes/Sec │ 0 B │ 0 B  │ 402 kB │ 943 kB │ 409 kB  │ 401 kB  │ 7.04 kB │
└───────────┴─────┴──────┴────────┴────────┴─────────┴─────────┴─────────┘
┌──────┬───────┐
│ Code │ Count │
├──────┼───────┤
│ 200  │ 649   │
├──────┼───────┤
│ 503  │ 77741 │
└──────┴───────┘

Req/Bytes counts sampled once per second.
# of samples: 60

649 2xx responses, 77741 non 2xx responses
82k requests in 60.08s, 24.5 MB read
1k errors (1k timeouts)
```

There is still a critical situation, because we can see some timeouts,
but the load surge is successfully mitigated.

## `server-load-aware.js`

```bash
$ autocannon -c 10 -r 50 -d 60 --renderStatusCodes http://127.0.0.1:3000
Running 60s test @ http://127.0.0.1:3000
10 connections


┌─────────┬──────┬────────┬────────┬────────┬───────────┬──────────┬────────┐
│ Stat    │ 2.5% │ 50%    │ 97.5%  │ 99%    │ Avg       │ Stdev    │ Max    │
├─────────┼──────┼────────┼────────┼────────┼───────────┼──────────┼────────┤
│ Latency │ 6 ms │ 126 ms │ 249 ms │ 254 ms │ 126.61 ms │ 74.19 ms │ 274 ms │
└─────────┴──────┴────────┴────────┴────────┴───────────┴──────────┴────────┘
┌───────────┬─────────┬─────────┬─────────┬─────────┬─────────┬─────────┬─────────┐
│ Stat      │ 1%      │ 2.5%    │ 50%     │ 97.5%   │ Avg     │ Stdev   │ Min     │
├───────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Req/Sec   │ 38      │ 38      │ 39      │ 40      │ 47.04   │ 60.28   │ 38      │
├───────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Bytes/Sec │ 6.69 kB │ 6.69 kB │ 6.87 kB │ 7.04 kB │ 8.28 kB │ 10.6 kB │ 6.69 kB │
└───────────┴─────────┴─────────┴─────────┴─────────┴─────────┴─────────┴─────────┘
┌──────┬───────┐
│ Code │ Count │
├──────┼───────┤
│ 200  │ 2822  │
└──────┴───────┘

Req/Bytes counts sampled once per second.
# of samples: 60

3k requests in 60.06s, 497 kB read
```

---

```bash
$ autocannon -c 50 -r 50 -d 60 --renderStatusCodes http://127.0.0.1:3000
Running 60s test @ http://127.0.0.1:3000
50 connections


┌─────────┬──────┬────────┬─────────┬─────────┬───────────┬───────────┬─────────┐
│ Stat    │ 2.5% │ 50%    │ 97.5%   │ 99%     │ Avg       │ Stdev     │ Max     │
├─────────┼──────┼────────┼─────────┼─────────┼───────────┼───────────┼─────────┤
│ Latency │ 1 ms │ 183 ms │ 1101 ms │ 1172 ms │ 310.07 ms │ 341.71 ms │ 1257 ms │
└─────────┴──────┴────────┴─────────┴─────────┴───────────┴───────────┴─────────┘
┌───────────┬─────────┬─────────┬────────┬────────┬─────────┬────────┬─────────┐
│ Stat      │ 1%      │ 2.5%    │ 50%    │ 97.5%  │ Avg     │ Stdev  │ Min     │
├───────────┼─────────┼─────────┼────────┼────────┼─────────┼────────┼─────────┤
│ Req/Sec   │ 39      │ 40      │ 1826   │ 2551   │ 1415.09 │ 986.99 │ 39      │
├───────────┼─────────┼─────────┼────────┼────────┼─────────┼────────┼─────────┤
│ Bytes/Sec │ 6.87 kB │ 7.04 kB │ 322 kB │ 449 kB │ 249 kB  │ 174 kB │ 6.86 kB │
└───────────┴─────────┴─────────┴────────┴────────┴─────────┴────────┴─────────┘
┌──────┬───────┐
│ Code │ Count │
├──────┼───────┤
│ 200  │ 84891 │
└──────┴───────┘

Req/Bytes counts sampled once per second.
# of samples: 60

87k requests in 60.06s, 14.9 MB read
```

Conclusions:
* massive amount of req/s completed, even in case of a surge in traffic

---

```bash
$ autocannon -c 50 -r 50 -d 60 -t 1 --renderStatusCodes http://127.0.0.1:3000
Running 60s test @ http://127.0.0.1:3000
50 connections


┌─────────┬──────┬───────┬────────┬────────┬───────────┬───────────┬─────────┐
│ Stat    │ 2.5% │ 50%   │ 97.5%  │ 99%    │ Avg       │ Stdev     │ Max     │
├─────────┼──────┼───────┼────────┼────────┼───────────┼───────────┼─────────┤
│ Latency │ 1 ms │ 14 ms │ 770 ms │ 856 ms │ 170.59 ms │ 231.81 ms │ 1001 ms │
└─────────┴──────┴───────┴────────┴────────┴───────────┴───────────┴─────────┘
┌───────────┬─────┬──────┬────────┬────────┬─────────┬─────────┬────────┐
│ Stat      │ 1%  │ 2.5% │ 50%    │ 97.5%  │ Avg     │ Stdev   │ Min    │
├───────────┼─────┼──────┼────────┼────────┼─────────┼─────────┼────────┤
│ Req/Sec   │ 0   │ 0    │ 1345   │ 2551   │ 1254.34 │ 1016.18 │ 21     │
├───────────┼─────┼──────┼────────┼────────┼─────────┼─────────┼────────┤
│ Bytes/Sec │ 0 B │ 0 B  │ 237 kB │ 449 kB │ 221 kB  │ 179 kB  │ 3.7 kB │
└───────────┴─────┴──────┴────────┴────────┴─────────┴─────────┴────────┘
┌──────┬───────┐
│ Code │ Count │
├──────┼───────┤
│ 200  │ 75250 │
└──────┴───────┘

Req/Bytes counts sampled once per second.
# of samples: 60

79k requests in 60.06s, 13.2 MB read
1k errors (1k timeouts)
```

Conclusions:
* massive amount of req/s completed, even in case of a surge in traffic
* some timeout still occurring because the system is not predictive,
  it takes a bit of time to close the circuit breaker
